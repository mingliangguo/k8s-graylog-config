apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-gelf
  labels:
    app: kube-gelf
data:
  GELF_HOST: "graylog3"
  GELF_UDP_PORT: "12201"
  GELF_TCP_PORT: "12202"
  GELF_PROTOCOL: "udp"
  fluent.conf: |
    <label @FLUENT_LOG>
      <match fluent.**>
        @type null
      </match>
    </label>

    # Valid log_level's are: fatal, error, warn, info, debug, trace
    <system>
      log_level info
    </system>

    <source>
      @type tail
      path /var/log/containers/ming-*.log,/var/log/containers/ming*.log

      pos_file /pos/ming-containers.pos
      # time_key timestamp
      # time_format %Y-%m-%dT%H:%M:%S.%NZ
      # time_format %Y-%m-%d %H:%M:%S.%3N
      tag kubernetes.*
      read_from_head true
      enable_stat_watcher false
      <parse>
       @type multi_format
       <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
       </pattern>
       <pattern>
         # Sample logs
         # 2020-08-03T01:28:52.731548586Z stdout F 2020-08-03 01:28:52.730  INFO 1 --- [nio-8080-exec-4] hello.Application                        : hello: hudson
         format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
         time_format %Y-%m-%dT%H:%M:%S.%N%:z
       </pattern>
       <pattern>
       format none
       </pattern>
     </parse>
    </source>

    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
      watch false
    </filter>

    #
    # Fixes parsing nested json in the docker json logs
    <filter kubernetes.**>
      @id filter_parser
      @type parser
      key_name log
      reserve_data true
      remove_key_name_field true
      replace_invalid_sequence true
      reserve_time true
      emit_invalid_record_to_error true
      <parse>
        @type multi_format
        <pattern>
          format json
          json_parser json
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    <filter kubernetes.**>
      @type record_transformer
      enable_ruby true
      <record>
        hostname "#{ENV['NODENAME']}"
        serverTime ${ require 'time'; Time.now.utc.iso8601(3) }
        namespace ${record['kubernetes']['namespace_name']}
        podname ${record["kubernetes"]["pod_name"]}
        container_name ${record["kubernetes"]["container_name"]}
        data_center "kind"
      </record>
      remove_keys $.kubernetes.pod_id,$.kubernetes.namespace_id,$.kubernetes.container_image_id,$.kubernetes.master_url
    </filter>
    ### NOT COLLECT LOGS with log_type=audit ###
    <match kubernetes.**>
      @type rewrite_tag_filter
      <rule>
        key log_type
        pattern /audit/
        tag audit.logs
      </rule>
      <rule>
        key log_type
        pattern /audit/
        invert  true
        tag app.logs
      </rule>
    </match>

    <match **fluent**>
      @type null
    </match>

    <match **kube-system**>
      @type null
    </match>

    <match **monitoring**>
      @type null
    </match>

    <match **cert-manager**>
      @type null
    </match>

    <match **efs-staging**>
      @type null
    </match>

    <match app.logs>
       @type copy
       <store>
         @type gelf
         include_tag_key true
         host "#{ENV['FLUENT_GRAYLOG_HOST']}"
         port "#{ENV['FLUENT_GRAYLOG_UDP_PORT']}"
         protocol "udp"
         flush_interval 5s
         num_threads 2
         use_record_host true
         buffer_chunk_limit 4096K
         buffer_queue_limit 512
         max_retry_wait 300
       </store>
    </match>

    <match audit.logs>
       @type copy
       <store>
         @type gelf
         include_tag_key true
         host "#{ENV['FLUENT_GRAYLOG_HOST']}"
         port "#{ENV['FLUENT_GRAYLOG_TCP_PORT']}"
         protocol "tcp"
         flush_interval 5s
         num_threads 2
         use_record_host true
         buffer_chunk_limit 4096K
         buffer_queue_limit 512
         max_retry_wait 300
       </store>
    </match>

